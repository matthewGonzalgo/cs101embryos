{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtrCdfqQvquZ"
   },
   "source": [
    "#### Import and set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MZPg9BMnH3Q4",
    "outputId": "6835f54c-36bf-434a-bd51-10345497a3e3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from skimage.io import imread\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms, utils\n",
    "from torchsummary import summary\n",
    "import torch.optim as optim\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ix1bVUmQy98"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUUMbl8LMCzv"
   },
   "outputs": [],
   "source": [
    "root_directory = Path(\"/content/\")\n",
    "drive_path = root_directory / 'drive/MyDrive' / 'CS101' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHNnunH0H8RQ",
    "outputId": "5c805836-63be-4631-c63c-365c19805cf8"
   },
   "outputs": [],
   "source": [
    "# Path to zip file in my drive\n",
    "!unzip '/content/drive/My Drive/CS101/CS101_z_anish.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jvG90awHJxf4",
    "outputId": "3eeee9a6-a4b5-437a-d032-db68f303ef0f"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"pytorch_unet.py\"):\n",
    "  if not os.path.exists(\"pytorch_unet\"):\n",
    "    !git clone https://github.com/usuyama/pytorch-unet.git\n",
    "\n",
    "  %cd pytorch-unet\n",
    "\n",
    "import pytorch_unet\n",
    "%cd /content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQiOIm-6MTAn"
   },
   "source": [
    "#### Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nr8dXZXuIFhg"
   },
   "outputs": [],
   "source": [
    "class EmbryoDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        image_list_file = os.path.join(self.data_dir, 'DIC.list') \n",
    "        gt_list_file = os.path.join(self.data_dir, 'seg.list')\n",
    "        fl_list_file = os.path.join(self.data_dir, 'fluo.list')\n",
    "\n",
    "        with open(image_list_file, 'r') as f:\n",
    "            self.image_list = f.read().splitlines()\n",
    "        with open(gt_list_file, 'r') as f:\n",
    "            self.gt_list = f.read().splitlines()\n",
    "        with open(fl_list_file, 'r') as f:\n",
    "            self.fluo_list = f.read().splitlines()\n",
    "\n",
    "        onset_df = pd.read_excel(drive_path / 'Time_Annotation.xlsx')\n",
    "        self.onset_dict = dict(zip(onset_df[\"embryo_index\"].astype(int), onset_df[\"onset\"].astype(int)))\n",
    "        self.z_dict = dict(zip(onset_df[\"embryo_index\"].astype(int), onset_df[\"z_num\"].astype(int)))\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.length = len(self.image_list)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.data_dir, self.image_list[index]) + '.npy'\n",
    "        gt_path = os.path.join(self.data_dir, self.gt_list[index])\n",
    "        fluo_path = os.path.join(self.data_dir, self.fluo_list[index])\n",
    "        try:\n",
    "            image = np.load(image_path)\n",
    "        except:\n",
    "            print(image_path)\n",
    "        gt = imread(gt_path, as_gray=True)\n",
    "        fluo = imread(fluo_path, as_gray=True)\n",
    "        image = self.image_transform(image)\n",
    "        gt = self.gt_transform(gt)\n",
    "\n",
    "        # Extract embryo image details\n",
    "        embryo_details = gt_path.split('/')\n",
    "        embryo_num = int(embryo_details[-2][6:])\n",
    "        timestep = int(embryo_details[-1][1:-4])\n",
    "        onset = self.onset_dict[embryo_num]\n",
    "\n",
    "        tags = {\"embryo_num\": embryo_num, \"timestep\": timestep, \"onset\": onset}\n",
    "        return image, gt, fluo, tags\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def image_transform(self, image):\n",
    "        trans =  transforms.Normalize([0.4111] * 32, [0.2077] * 32)\n",
    "\n",
    "        image = image / 255.0\n",
    "        image = torch.from_numpy(image)\n",
    "        image = trans(image)\n",
    "        squeezed = torch.unsqueeze(image, 0)\n",
    "        return squeezed.float()\n",
    "\n",
    "    def gt_transform(self, gt):\n",
    "        gt = gt / 255.0\n",
    "        return torch.squeeze(torch.from_numpy(gt)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Y1jeomhIPSS"
   },
   "outputs": [],
   "source": [
    "# Instantiate train, validation, and test dataloaders\n",
    "train_set = EmbryoDataset(root_directory / 'trainset')\n",
    "test_set = EmbryoDataset(root_directory / 'testset')\n",
    "val_set = EmbryoDataset(root_directory / 'valset')\n",
    "\n",
    "D = 32 # Number of channels in input image\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "train_loader_not_shuffled = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {\"train\": train_loader, \"test\": test_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4rjiLVS5Ji7"
   },
   "source": [
    "#### Training helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6kbbzj0g5NgM",
    "outputId": "e9d6ab08-f36a-422d-a3d6-0e3bb45e49f0"
   },
   "outputs": [],
   "source": [
    "%cd pytorch-unet\n",
    "from loss import dice_loss\n",
    "%cd /content\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def print_metrics(metrics, epoch_samples, phase):\n",
    "    outputs = []\n",
    "    for k in metrics.keys():\n",
    "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
    "\n",
    "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
    "\n",
    "def calculate_pixel_metrics(pred, label):\n",
    "    '''\n",
    "    Calculate TP, FP, FN of one image\n",
    "    '''\n",
    "    TP = (pred * label).sum()    \n",
    "    FP = ((1-label) * pred).sum()\n",
    "    FN = (label * (1-pred)).sum()\n",
    "\n",
    "    return TP.item(), FP.item(), FN.item()\n",
    "\n",
    "def get_samples_for_viz(val_metrics, N, thresh):\n",
    "    '''\n",
    "    Find images with best/worst/median iou at the given thresh\n",
    "    '''\n",
    "    all_imgs_by_iou = []\n",
    "    for batch in val_metrics:\n",
    "        imgs = val_metrics[batch][thresh]\n",
    "        for pos in imgs:\n",
    "            info = imgs[pos]\n",
    "            iou = info[\"iou\"]\n",
    "            all_imgs_by_iou.append((iou, batch, pos, info))\n",
    "    \n",
    "    # Sort by lowest to highest\n",
    "    all_imgs_by_iou.sort(key=lambda x: x[0])\n",
    "    best_ious = all_imgs_by_iou[-N:]\n",
    "    worst_ious = all_imgs_by_iou[:N]\n",
    "\n",
    "    # computing strt, and end index for middle N\n",
    "    strt_idx = (len(all_imgs_by_iou) // 2) - (N // 2)\n",
    "    end_idx = (len(all_imgs_by_iou) // 2) + (N // 2)\n",
    "    \n",
    "    # slicing extracting middle elements\n",
    "    middle_ious = all_imgs_by_iou[strt_idx: end_idx]\n",
    "\n",
    "    return best_ious, middle_ious, worst_ious\n",
    "\n",
    "def show_img_sample(axs, batch, inputs, labels, fls, tags, model, ious, subplot_row, thresh):\n",
    "    for bound_iou, img_batch, pos, _ in ious:\n",
    "        if batch == img_batch:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            embryo_num = tags[\"embryo_num\"][pos]\n",
    "            timestep = tags[\"timestep\"][pos]\n",
    "            onset = tags[\"onset\"][pos]\n",
    "\n",
    "            preds_prob = model(inputs).detach()\n",
    "            preds = torch.where(preds_prob > thresh, 1.0, 0.0).int()\n",
    "\n",
    "            axs[subplot_row, 0].set_title(\"FL\")\n",
    "            axs[subplot_row, 0].imshow(fls[pos], cmap=\"gray\")\n",
    "            axs[subplot_row, 1].set_title(\"GT\")\n",
    "            axs[subplot_row, 1].imshow(labels[pos], cmap=\"gray\")\n",
    "            axs[subplot_row, 2].set_title(\"Model Output\".format(bound_iou))\n",
    "            axs[subplot_row, 2].imshow(preds_prob[pos].cpu().numpy(), cmap=\"gray\")\n",
    "            axs[subplot_row, 3].set_title(\"Prediction IOU: {}\".format(bound_iou))\n",
    "            axs[subplot_row, 3].imshow((preds[pos]).cpu().numpy(), cmap=\"gray\")\n",
    "            embryo_info_text = \"Embryo {}\\n Timestep {}\\n Onset {}\".format(embryo_num, timestep, onset)\n",
    "            axs[subplot_row, 4].text(0.5, 0.5, embryo_info_text, horizontalalignment='center', verticalalignment='center')\n",
    "\n",
    "            subplot_row += 1\n",
    "    return subplot_row\n",
    "\n",
    "def visualize_metrics(model, val_loader, val_metrics, N=2, non_boundary_metrics=False):\n",
    "    '''\n",
    "    Takes data in val_metrics and displays:\n",
    "        PR Curve\n",
    "        Images with highest iou\n",
    "        Images with lowest iou\n",
    "        Images with median iou\n",
    "        ?iou curve vs threshold\n",
    "    '''\n",
    "\n",
    "    # Compute PR curve and IoU scores\n",
    "    threshs = np.linspace(0, 1, num=101) # Set of thresholds to try\n",
    "    precisions = np.zeros_like(threshs)\n",
    "    recalls = np.zeros_like(threshs)\n",
    "\n",
    "    # Checks all thresholds and finda threshold that corresponds to best iou\n",
    "    max_iou = 0\n",
    "    curr_iou = 0\n",
    "    max_threshold = 0\n",
    "    num_images = len(val_loader) * batch_size\n",
    "    iou_per_thresh = []\n",
    "    for i in range(len(threshs)):\n",
    "        thresh = threshs[i]\n",
    "        for batch in val_metrics:\n",
    "            thresh_dict = val_metrics[batch][thresh]\n",
    "            for pos in thresh_dict:\n",
    "                curr_iou += thresh_dict[pos]['iou']\n",
    "                precisions[i] += thresh_dict[pos]['precision']\n",
    "                recalls[i] += thresh_dict[pos]['recall']\n",
    "        iou_per_thresh.append(curr_iou / num_images)\n",
    "        if curr_iou > max_iou:\n",
    "            max_iou = curr_iou\n",
    "            max_threshold = thresh\n",
    "        curr_iou = 0\n",
    "    \n",
    "    max_iou /= num_images\n",
    "    precisions /= num_images\n",
    "    recalls /= num_images\n",
    "\n",
    "    print(\"\\n###\")\n",
    "    print(\"Mean IoU at threshold {}: {}\".format(max_threshold, max_iou))\n",
    "    print(\"\\n###\")\n",
    "\n",
    "    # Get samples with best, middle, and worst ious\n",
    "    best_ious, middle_ious, worst_ious = get_samples_for_viz(val_metrics, N, max_threshold)\n",
    "\n",
    "    fig, axs = plt.subplots(7, 5, figsize=(35, 35))\n",
    "    \n",
    "    axs[0,0].set_title(\"Image PR Curve\")\n",
    "    axs[0,0].set_xlabel(\"Recall\")\n",
    "    axs[0,0].set_ylabel(\"Precision\")\n",
    "    axs[0,0].set_xlim([0,1])\n",
    "    axs[0,0].set_ylim([0,1])\n",
    "    axs[0,0].plot(recalls, precisions)\n",
    "\n",
    "    axs[0,2].set_title(\"IoU vs Threshold\")\n",
    "    axs[0,2].set_xlabel(\"Threshold\")\n",
    "    axs[0,2].set_ylabel(\"IoU\")\n",
    "    axs[0,2].set_xlim([0,1])\n",
    "    axs[0,2].set_ylim([0,1])\n",
    "    axs[0,2].plot(threshs, iou_per_thresh)\n",
    "\n",
    "    subplot_row = 1\n",
    "    dataloader_iterator = iter(val_loader)\n",
    "    for batch in range(len(val_loader)):\n",
    "        inputs, labels, fls, tags = next(dataloader_iterator)\n",
    "        subplot_row = show_img_sample(axs, batch, inputs, labels, fls, tags, model, best_ious, subplot_row, max_threshold)\n",
    "        subplot_row = show_img_sample(axs, batch, inputs, labels, fls, tags, model, middle_ious, subplot_row, max_threshold)\n",
    "        subplot_row = show_img_sample(axs, batch, inputs, labels, fls, tags, model, worst_ious, subplot_row, max_threshold)\n",
    "    plt.show()\n",
    "\n",
    "def populate_metrics(inputs, labels, preds_prob, batch_num, val_metrics):\n",
    "    '''\n",
    "    ASSUMES VAL_LOADER IS NOT SHUFFLED\n",
    "    Takes in batch and adds to the validation metrics\n",
    "    val_metrics layout {\n",
    "        batch_num: {\n",
    "            thresh: {\n",
    "                pos: {\n",
    "                    TP:\n",
    "                    FP:\n",
    "                    FN:\n",
    "                    iou:\n",
    "                    precision:\n",
    "                    recall:\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    threshs = np.linspace(0, 1, num=101) # Set of thresholds to try\n",
    "    SMOOTH = 1e-6\n",
    "    batch_dict = {}\n",
    "\n",
    "    for i, thresh in enumerate(threshs):\n",
    "        preds = torch.where(preds_prob > thresh, 1.0, 0.0).int()\n",
    "        thresh_dict = {}\n",
    "        for pos in range(labels.shape[0]):\n",
    "            pos_dict = {}\n",
    "            img_TP, img_FP, img_FN = calculate_pixel_metrics(preds[pos], labels[pos])\n",
    "\n",
    "            img_precision = (img_TP+SMOOTH) / (img_TP+img_FP+SMOOTH)\n",
    "            img_recall = (img_TP+SMOOTH) / (img_TP+img_FN+SMOOTH)\n",
    "            img_iou = (img_TP+SMOOTH) / (img_TP+img_FP+img_FN+SMOOTH)\n",
    "\n",
    "            pos_dict['TP'] = img_TP\n",
    "            pos_dict['FP'] = img_FP\n",
    "            pos_dict['FN'] = img_FN\n",
    "            pos_dict['iou'] = img_iou\n",
    "            pos_dict['precision'] = img_precision\n",
    "            pos_dict['recall'] = img_recall\n",
    "            thresh_dict[pos] = pos_dict\n",
    "        batch_dict[thresh] = thresh_dict\n",
    "    val_metrics[batch_num] = batch_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwZ-5M-Cp7gW"
   },
   "source": [
    "#### Declare Model and Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfuJw8V8Jf_i"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "from collections import OrderedDict\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, init_features=16):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose3d(\n",
    "            features * 16, features * 8, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose3d(\n",
    "            features * 8, features * 4, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose3d(\n",
    "            features * 4, features * 2, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose3d(\n",
    "            features * 2, features, kernel_size=2, stride=2\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "        self.final_pool = nn.MaxPool3d(kernel_size=(32, 1, 1), stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(\"x: {}\".format(x.shape))\n",
    "        enc1 = self.encoder1(x)\n",
    "        #print(\"Enc1: {}\".format(enc1.shape))\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        #print(\"Enc2: {}\".format(enc2.shape))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        #print(\"Enc3: {}\".format(enc3.shape))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "        #print(\"Enc4: {}\".format(enc4.shape))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "        #print(\"Bottleneck: {}\".format(bottleneck.shape))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        #print(\"upconv dec4: {}\".format(dec4.shape))\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        #print(\"cat dec4: {}\".format(dec4.shape))\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        #print(\"decoded dec4: {}\".format(dec4.shape))\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        z_stack = self.conv(dec1)\n",
    "        logits = self.final_pool(z_stack)\n",
    "        \n",
    "        # Make output (batch size) x H x W\n",
    "        logits = torch.squeeze(logits, dim=1)\n",
    "        logits = torch.squeeze(logits, dim=1)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv3d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm3d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv3d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm3d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIQFPitSKbHa"
   },
   "outputs": [],
   "source": [
    "class FocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(FocalTverskyLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1, alpha=0.75, beta=0.25, gamma=0.75):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = (inputs * targets).sum()    \n",
    "        FP = ((1-targets) * inputs).sum()\n",
    "        FN = (targets * (1-inputs)).sum()\n",
    "        \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = (1 - Tversky)**gamma\n",
    "                       \n",
    "        return FocalTversky\n",
    "\n",
    "def calc_loss(pred, target, metrics):\n",
    "    ft = FocalTverskyLoss()\n",
    "    loss = ft.forward(pred, target)\n",
    "    metrics['loss'] += loss.data.cpu().numpy()\n",
    "    return loss\n",
    "\n",
    "def train_model(model, optimizer, scheduler, checkpoint_path, num_epochs=25, start_epoch=0):\n",
    "    best_loss = 1e10\n",
    "\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        epoch_loss_full = defaultdict(float)\n",
    "        epoch_loss_dice = defaultdict(float)\n",
    "        epoch_loss_bce = defaultdict(float)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            metrics = defaultdict(float)\n",
    "            epoch_samples = 0\n",
    "            batch_num = -1\n",
    "\n",
    "            if phase == \"val\":\n",
    "                val_metrics = {}\n",
    "\n",
    "            for inputs, labels, _, _ in tqdm(dataloaders[phase]):\n",
    "                batch_num += 1\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = calc_loss(outputs, labels, metrics)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                epoch_samples += inputs.size(0)\n",
    "                iteration = epoch_samples // inputs.size(0)\n",
    "\n",
    "                if phase == \"val\":\n",
    "                    populate_metrics(inputs, labels, outputs, batch_num, val_metrics)\n",
    "                    \n",
    "                if iteration % 50 == 1 and phase == 'train':\n",
    "                    #torch.save(model.state_dict(), os.path.join(checkpoint_path, '{}_{}.pth'.format(epoch, iteration)))\n",
    "                    print_metrics(metrics, epoch_samples, phase)\n",
    "\n",
    "            print_metrics(metrics, epoch_samples, phase)\n",
    "            epoch_loss = metrics['loss'] / epoch_samples\n",
    "\n",
    "            if phase == 'train':\n",
    "                # Update the learning rate\n",
    "                scheduler.step()\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    print(\"LR\", param_group['lr'])\n",
    "                \n",
    "                # Log training loss\n",
    "                epoch_loss_full['train'] = metrics['loss'] / epoch_samples\n",
    "                # epoch_loss_bce['train'] = metrics['bce'] / epoch_samples\n",
    "                # epoch_loss_dice['train'] = metrics['dice'] / epoch_samples\n",
    "                \n",
    "\n",
    "            if phase == \"val\":\n",
    "                # Log validation loss\n",
    "                epoch_loss_full['val'] = metrics['loss'] / epoch_samples\n",
    "                # epoch_loss_bce['val'] = metrics['bce'] / epoch_samples\n",
    "                # epoch_loss_dice['val'] = metrics['dice'] / epoch_samples\n",
    "\n",
    "                # Visualize model results\n",
    "                if epoch % 5 == 1:\n",
    "                    print(\"Epoch {}: Training visualizations\".format(epoch))\n",
    "                    train_metrics = {}\n",
    "                    batch_num = -1\n",
    "                    for inputs, labels, _, _ in tqdm(train_loader_not_shuffled):\n",
    "                        batch_num += 1\n",
    "                        inputs = inputs.to(device)\n",
    "                        labels = labels.to(device)\n",
    "                        with torch.set_grad_enabled(phase == 'train'):\n",
    "                            outputs = model(inputs)\n",
    "                        populate_metrics(inputs, labels, outputs, batch_num, train_metrics)\n",
    "                    visualize_metrics(model, train_loader_not_shuffled, train_metrics)\n",
    "\n",
    "                print(\"Epoch {}: Validation visualizations\".format(epoch))\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    visualize_metrics(model, dataloaders[phase], val_metrics)\n",
    "\n",
    "\n",
    "            if phase == 'val':\n",
    "                if epoch_loss < best_loss:\n",
    "                    # save the model weights\n",
    "                    print(f\"saving best model to {checkpoint_path}\")\n",
    "                    best_loss = epoch_loss\n",
    "                    torch.save(model.state_dict(), os.path.join(checkpoint_path, 'best_{}.pth'.format(epoch)))\n",
    "                else:\n",
    "                    torch.save(model.state_dict(), os.path.join(checkpoint_path, '{}.pth'.format(epoch)))\n",
    "        \n",
    "        # Plot Loss\n",
    "        writer.add_scalars('Loss', epoch_loss_full, epoch)\n",
    "        # writer.add_scalars('BCE Loss', epoch_loss_bce, epoch)\n",
    "        # writer.add_scalars('Dice Loss', epoch_loss_dice, epoch)\n",
    "\n",
    "\n",
    "        #torch.save(model.state_dict(), os.path.join(checkpoint_path, '{}.pth'.format(epoch)))\n",
    "        time_elapsed = time.time() - since\n",
    "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best val loss: {:4f}'.format(best_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRsJ1npqhZUT"
   },
   "source": [
    "#### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXCRdQK3hL66",
    "outputId": "5b087923-adaa-411b-b7e9-354311be9aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "\n",
    "model = UNet().to(device)\n",
    "#summary(model, input_size=(1, 32, 512, 512), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwVNHEfOhSNz"
   },
   "outputs": [],
   "source": [
    "# Run if you want to load model from checkpoint\n",
    "\n",
    "model_path = drive_path / 'exps' / 'anish' / 'exp20' / 'checkpoints' / 'best_7.pth'\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKQm3hNZhme6"
   },
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EuGTgsaV9CbZ",
    "outputId": "3ad3496c-521f-43fd-9f24-8f6d0db5efff"
   },
   "outputs": [],
   "source": [
    "log_path = drive_path / 'exps' / 'anish' / 'exp20' / 'logs'\n",
    "checkpoint_path = drive_path / 'exps' / 'anish' / 'exp20' / 'checkpoints'\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "start_epoch = 0\n",
    "optimizer_ft = optim.Adam(model.parameters(), lr=0.00005)\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)\n",
    "for i in range(start_epoch):\n",
    "    exp_lr_scheduler.step()\n",
    "train_model(model, optimizer_ft, exp_lr_scheduler, checkpoint_path, num_epochs=30, start_epoch = start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVZ0_s6fQ9G-"
   },
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "writer.close()\n",
    "%tensorboard --logdir='/content/drive/MyDrive/CS101/exps/anish/exp20/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEjwMr_TyFWu"
   },
   "source": [
    "#### Evaluate performance on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXuEJj7WI7d7"
   },
   "outputs": [],
   "source": [
    "val_metrics = {}\n",
    "model.eval()\n",
    "batch_num = -1\n",
    "for inputs, labels, fls, _ in tqdm(val_loader):\n",
    "    batch_num += 1\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    populate_metrics(inputs, labels, outputs, batch_num, val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYuCxpDyJm6X"
   },
   "outputs": [],
   "source": [
    "visualize_metrics(model, val_loader, val_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGHKgkWLNCRD"
   },
   "source": [
    "#### Evaluate performance on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsHTbLb_NE-Y"
   },
   "outputs": [],
   "source": [
    "train_metrics = {}\n",
    "model.eval()\n",
    "batch_num = -1\n",
    "for inputs, labels, _ in tqdm(train_loader_not_shuffled):\n",
    "    batch_num += 1\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    populate_metrics(inputs, labels, outputs, batch_num, train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7AZ3KUyNJ00"
   },
   "outputs": [],
   "source": [
    "visualize_metrics(model, train_loader_not_shuffled, train_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwbmF9RI0GeM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "EtrCdfqQvquZ",
    "eQiOIm-6MTAn",
    "O4rjiLVS5Ji7",
    "wwZ-5M-Cp7gW",
    "DRsJ1npqhZUT",
    "PEjwMr_TyFWu",
    "aGHKgkWLNCRD"
   ],
   "machine_shape": "hm",
   "name": "exp20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
